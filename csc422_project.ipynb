{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "\n",
    "def load_cifar10():\n",
    "    # Load the CIFAR-10 dataset\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def preprocess_cifar10(x_train, x_test, batch_size=32):\n",
    "    # Resize the images to 128x128 pixels\n",
    "    x_train_resized = np.zeros((len(x_train), 128, 128, 3), dtype=np.uint8)\n",
    "    x_test_resized = np.zeros((len(x_test), 128, 128, 3), dtype=np.uint8)\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        batch = x_train[i:i+batch_size]\n",
    "        x_train_resized[i:i+batch_size] = np.array([cv2.resize(img, (128, 128)) for img in batch])\n",
    "    for i in range(0, len(x_test), batch_size):\n",
    "        batch = x_test[i:i+batch_size]\n",
    "        x_test_resized[i:i+batch_size] = np.array([cv2.resize(img, (128, 128)) for img in batch])\n",
    "\n",
    "    # Preprocess the images for the VGG16 model\n",
    "    x_train_preprocessed = np.zeros((len(x_train_resized), 128, 128, 3), dtype=np.float32)\n",
    "    x_test_preprocessed = np.zeros((len(x_test_resized), 128, 128, 3), dtype=np.float32)\n",
    "    for i in range(0, len(x_train_resized), batch_size):\n",
    "        batch = x_train_resized[i:i+batch_size]\n",
    "        x_train_preprocessed[i:i+batch_size] = np.array([preprocess_input(img) for img in batch])\n",
    "    for i in range(0, len(x_test_resized), batch_size):\n",
    "        batch = x_test_resized[i:i+batch_size]\n",
    "        x_test_preprocessed[i:i+batch_size] = np.array([preprocess_input(img) for img in batch])\n",
    "\n",
    "    return x_train_preprocessed, x_test_preprocessed\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "x_train, y_train, x_test, y_test = load_cifar10()\n",
    "\n",
    "# Preprocess the dataset\n",
    "x_train_preprocessed, x_test_preprocessed = preprocess_cifar10(x_train, x_test, batch_size=32)\n",
    "\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Use the VGG16 model to extract features from the images\n",
    "x_train_features = vgg16.predict(x_train_preprocessed)\n",
    "x_test_features = vgg16.predict(x_test_preprocessed)\n",
    "\n",
    "# Flatten the feature vectors\n",
    "x_train_flattened = x_train_features.reshape(x_train_features.shape[0], -1)\n",
    "x_test_flattened = x_test_features.reshape(x_test_features.shape[0], -1)\n",
    "\n",
    "# Perform k-means clustering on the feature vectors\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "y_train_pred = kmeans.fit_predict(x_train_flattened)\n",
    "\n",
    "# Compute the purity score of the clustering\n",
    "def purity_score(y_true, y_pred):\n",
    "    # Compute the contingency matrix\n",
    "    contingency = np.zeros((10, 10))\n",
    "    for i in range(len(y_true)):\n",
    "        contingency[int(y_true[i]), int(y_pred[i])] += 1\n",
    "\n",
    "    # Compute the purity score\n",
    "    purity = np.sum(np.amax(contingency, axis=1)) / np.sum(contingency)\n",
    "    return purity\n",
    "\n",
    "purity = purity_score(y_train, y_train_pred)\n",
    "print(\"The purity score of the clustering is:\", purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Choose two images from the training set \n",
    "img1 = x_train_preprocessed[2]\n",
    "img2 = x_train_preprocessed[2]\n",
    "\n",
    "# Extract the features of the two images using the pre-trained VGG16 model\n",
    "img1_features = vgg16.predict(img1.reshape(1, 128, 128, 3)).flatten()\n",
    "img2_features = vgg16.predict(img2.reshape(1, 128, 128, 3)).flatten()\n",
    "\n",
    "# Calculate the cosine similarity between the feature vectors of the two images\n",
    "similarity = cosine_similarity(img1_features.reshape(1, -1), img2_features.reshape(1, -1))[0][0]\n",
    "\n",
    "print(\"The cosine similarity between the two images is:\", similarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the first image in the training set\n",
    "plt.imshow(x_train[2])\n",
    "plt.show()\n",
    "\n",
    "# Display the second image in the training set\n",
    "plt.imshow(x_train[2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
